######Логистический анализ данных####

library(ggplot2) #библиотека для визуализации

df <- read.csv('students.csv',sep=';')

#данные о студентах, переменные отвечают за пол студента, его баллы по дисциплинам,показатель получил ли студент красный диплом или нет(N-не получил,Y-получил).

#С помощью логистической регрессии предскажем, получит ли студент с новыми данными(пол,баллы) красный диплом или нет.

#вызываем структуру данных:
str(df) 

#из структуры видно, что переменные gender и hon имеют тип character. Для дальнейшего анализа необходимо перевести их в factor:

df$gender <- as.factor(df$gender)
df$hon <- as.factor(df$hon)

#посмотрим на матрицу взаимосвязи переменных:
pairs(df)

#Видно,что read,write,math сильно кррелируют между собой

#загрузим библиотеку для того,чтобы посмотреть коэф.корреляции:
library(psych)


#посмотрим коэф.корреляции только у количественных перемееных
cor <- corr.test(df[,2:4])

cor$r 
cor$p

#для избежания мультиколлинеарности не будем включать переменную write в анализ

#посмотрим есть ли выбросы у наших независимых количественных переменных:
ggplot(df,aes(hon,math))+geom_boxplot()
ggplot(df,aes(hon,read))+geom_boxplot()

#из графика boxplot видно,что в переменной read имеются выбросы

#воспользуемся функцией удаления выбросов

outliers.rm <- function(x){
  
  x <- x[x<1.5*IQR(x)+quantile(x,0.75)&x>quantile(x,0.25)-1.5*IQR(x)]
  boxplot(x)
  return(x)
}

#в качестве аргумента функции будет наша переменная с выбросами
outliers.rm(df$read)


#убеждаемся,что выбросов больше нет
ggplot(df,aes(hon,math))+geom_boxplot()


#строим график рассеивания, по оси X -баллы read,Y-баллы math, красным цветом - female,зеленым -  male, делаем разбивку графика по показателю hon:
ggplot(df,aes(read,math,col=gender))+geom_point()+facet_grid(.~hon)


#из графика видно,что связь положительная между read и math(как мы уже убедились выше), плюс можно отметить,что женщины получают красный диплом чаще,чем мужчины

#cтроим логистическую модель:
fit <- glm(hon~gender*math*read,df,family="binomial")

#с помощью step выбираем оптимальный вариант модели:
step(fit,direction = 'backward')

#оптимальная модель:
fit <- glm(hon~gender+math+math:read,df,family="binomial")

summary(fit)

#можно вызвать и посмотреть отдельно на коэф.логистической регрессии:
fit$coefficients 

#с помощью exp можно посмотреть отношение шансов(odds)
exp(fit$coefficients)

#посмотрим вероятность получить красный диплом для первых 6 испытуемых
head(predict(fit,type="response"))

#добавим в наш df переменную с вероятностью получить красный диплом
df$prob <- predict(fit,type="response")


#теперь необходимо классифицировать вероятность в значение:получит студент диплом или нет. Для этого необходимо выбрать оптимальный порог вероятности.Воспользуемся кривой ROC:

library(ROCR)

#данные вероятности и реальные значения:
pred_fit <- prediction(df$prob,df$hon)

#рассчитываем true positive rate и false positive rate:
perf_fit <- performance(pred_fit,"tpr","fpr")

#ROC кривая:
plot(perf_fit,colorize=T,print.cutoffs.at=seq(0.1,by=0.1),lwd=2) 

#посмотрим на  площадь под кривой:
auc <- performance(pred_fit,measure = "auc")

str(auc) #площадь 0.866

#создадим переменную, в которой будет соотношение порога вероятности и специфичности классификатора:
perf3 <- performance(pred_fit,x.measure = "cutoff",measure = "spec")

#посмотрим на график соотношения порога вероятности и специфичности
plot(perf3,col="red",lwd=2)

#создадим переменную, в которой будет соотношение порога вероятности и чувствительности классификатора:
perf4 <- performance(pred_fit,x.measure = "cutoff",measure = "sens")

#добавим эту кривую на график
plot(add=T,perf4,col="green",lwd=2)

#создадим переменную, в которой будет соотношение порога вероятности и общей эффективности классификатора:
perf5 <- performance(pred_fit,x.measure = "cutoff",measure = "acc")

#опять же доавим кривую на график
plot(add=T,perf5,lwd=2)

#добавим легенду графику
legend(x=0.2,y=0.3,c("spec","sens","accur"),lty = 1,col=c('red','green','black'),bty='n',cex=1,lwd=2)


#по графику видно, что все три кривые перескаются в одной точке. Значение порога вероятности в этой точке = 0.22 - это и будет оптимальное значение 

#вертикальная линия,подтверждающая вышесказанное:
abline(v=0.22,lwd=1)

#теперь можно классифицировать нашу вероятность в значения - Y или N
df$pred_resp <- factor(ifelse(df$prob>0.22,1,0),labels = c("N","Y"))

#в новой переменной предсказанные значения получения  красного диплома

#теперь можно доавить переменную, которая проверяет наши предсказания:1-верно предсказано,0 - неверно
df$correct <- ifelse(df$pred_resp==df$hon,1,0)

#в заключении можно посмотреть процент правильно предсказанных результатов:
mean(df$correct)

#процент правильно предсказанных значений равен 79.3 (что также видно на ROC кривой для порога 0.22)

#теперь можно проверить нашу модель на тестовых данных

#загрузим тестовые данные такой же структуры, что и наш исходный df
test_df <- read.csv("test.csv",sep=";")

#предскажем значения Y и N для тестовых данных:
test_df$hon_pred <- predict(fit,newdata = test_df,type="response")
test_df$hon_pred <- factor(ifelse(test_df$hon_pred>0.22,1,0),labels = c("N","Y"))

#проверим наши предсказанные значения
test_df$correct <- ifelse(test_df$hon==test_df$hon_pred,1,0)
mean(test_df$correct)

#процент правильно предсказанных значений равен 78